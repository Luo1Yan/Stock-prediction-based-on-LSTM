import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import os
import warnings

# è®¾ç½®TensorFlowæ—¥å¿—çº§åˆ«ï¼Œéšè—ä¿¡æ¯æ€§æ—¥å¿—
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=å…¨éƒ¨æ—¥å¿—, 1=éšè—INFO, 2=éšè—INFOå’ŒWARNING, 3=åªæ˜¾ç¤ºERROR
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

class StockPricePredictor:
    def __init__(self, sequence_length=60):
        """
        åˆå§‹åŒ–è‚¡ç¥¨ä»·æ ¼é¢„æµ‹å™¨
        
        Args:
            sequence_length: ç”¨äºé¢„æµ‹çš„å†å²æ•°æ®é•¿åº¦
        """
        self.sequence_length = sequence_length
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.model = None
        
    def generate_stock_data(self, days=1030, start_price=100):
        """
        ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®ï¼ˆåŒ…å«æœªæ¥30å¤©ç”¨äºå¯¹æ¯”ï¼‰
        
        Args:
            days: ç”Ÿæˆæ•°æ®çš„å¤©æ•°ï¼ˆé»˜è®¤1030å¤©ï¼š1000å¤©å†å²æ•°æ® + 30å¤©æœªæ¥æ•°æ®ï¼‰
            start_price: èµ·å§‹ä»·æ ¼
            
        Returns:
            DataFrame: åŒ…å«æ—¥æœŸå’Œä»·æ ¼çš„æ•°æ®æ¡†
        """
        np.random.seed(42)
        
        # ç”Ÿæˆæ—¥æœŸåºåˆ—
        dates = pd.date_range(start='2020-01-01', periods=days, freq='D')
        
        # ç”Ÿæˆä»·æ ¼æ•°æ®ï¼ˆå¸¦è¶‹åŠ¿å’Œéšæœºæ³¢åŠ¨ï¼‰
        prices = [start_price]
        
        for i in range(1, days):
            # æ·»åŠ è¶‹åŠ¿ï¼ˆè½»å¾®ä¸Šå‡ï¼‰
            trend = 0.0005
            # æ·»åŠ éšæœºæ³¢åŠ¨
            volatility = np.random.normal(0, 0.02)
            # æ·»åŠ å‘¨æœŸæ€§æ³¢åŠ¨
            seasonal = 0.01 * np.sin(2 * np.pi * i / 252)  # å¹´åº¦å‘¨æœŸ
            
            # è®¡ç®—ä¸‹ä¸€ä¸ªä»·æ ¼
            change = trend + volatility + seasonal
            new_price = prices[-1] * (1 + change)
            prices.append(max(new_price, 1))  # ç¡®ä¿ä»·æ ¼ä¸ä¸ºè´Ÿ
        
        # åˆ›å»ºDataFrame
        data = pd.DataFrame({
            'Date': dates,
            'Price': prices
        })
        
        return data
    
    def prepare_data(self, data, train_ratio=0.8, future_days=30):
        """
        å‡†å¤‡è®­ç»ƒã€æµ‹è¯•å’Œæœªæ¥çœŸå®æ•°æ®
        
        Args:
            data: è‚¡ç¥¨ä»·æ ¼æ•°æ®
            train_ratio: è®­ç»ƒæ•°æ®æ¯”ä¾‹
            future_days: æœªæ¥é¢„æµ‹å¤©æ•°
            
        Returns:
            tuple: (X_train, y_train, X_test, y_test, train_data, test_data, future_data)
        """
        # åˆ†ç¦»å†å²æ•°æ®å’Œæœªæ¥çœŸå®æ•°æ®
        historical_data = data.iloc[:-future_days].copy()  # å‰1000å¤©
        future_real_data = data.iloc[-future_days:].copy()  # å30å¤©
        
        # æå–å†å²ä»·æ ¼æ•°æ®
        prices = historical_data['Price'].values.reshape(-1, 1)
        
        # æ•°æ®æ ‡å‡†åŒ–
        scaled_prices = self.scaler.fit_transform(prices)
        
        # åˆ›å»ºåºåˆ—æ•°æ®
        X, y = [], []
        for i in range(self.sequence_length, len(scaled_prices)):
            X.append(scaled_prices[i-self.sequence_length:i, 0])
            y.append(scaled_prices[i, 0])
        
        X, y = np.array(X), np.array(y)
        
        # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        train_size = int(len(X) * train_ratio)
        
        X_train = X[:train_size]
        y_train = y[:train_size]
        X_test = X[train_size:]
        y_test = y[train_size:]
        
        # é‡å¡‘æ•°æ®ä¸ºLSTMè¾“å…¥æ ¼å¼ [samples, time steps, features]
        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
        
        # ä¿å­˜åŸå§‹æ•°æ®ç”¨äºå¯è§†åŒ–
        train_data = historical_data.iloc[:train_size + self.sequence_length]
        test_data = historical_data.iloc[train_size + self.sequence_length:]
        
        return X_train, y_train, X_test, y_test, train_data, test_data, future_real_data
    
    def build_model(self, units=50, dropout_rate=0.2, learning_rate=0.001):
        """
        æ„å»ºLSTMæ¨¡å‹
        
        Args:
            units: LSTMå•å…ƒæ•°é‡
            dropout_rate: Dropoutæ¯”ä¾‹
            learning_rate: å­¦ä¹ ç‡
        """
        self.model = Sequential([
            # ç¬¬ä¸€å±‚LSTM
            LSTM(units=units, return_sequences=True, 
                 input_shape=(self.sequence_length, 1)),
            Dropout(dropout_rate),
            
            # ç¬¬äºŒå±‚LSTM
            LSTM(units=units, return_sequences=True),
            Dropout(dropout_rate),
            
            # ç¬¬ä¸‰å±‚LSTM
            LSTM(units=units),
            Dropout(dropout_rate),
            
            # è¾“å‡ºå±‚
            Dense(units=1)
        ])
        
        # ç¼–è¯‘æ¨¡å‹
        optimizer = Adam(learning_rate=learning_rate)
        self.model.compile(optimizer=optimizer, loss='mean_squared_error')
        
        return self.model
    
    def train_model(self, X_train, y_train, X_test, y_test, 
                   epochs=100, batch_size=32, verbose=1):
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X_train, y_train: è®­ç»ƒæ•°æ®
            X_test, y_test: æµ‹è¯•æ•°æ®
            epochs: è®­ç»ƒè½®æ•°
            batch_size: æ‰¹æ¬¡å¤§å°
            verbose: è¯¦ç»†ç¨‹åº¦
            
        Returns:
            History: è®­ç»ƒå†å²
        """
        # æ—©åœå›è°ƒ
        early_stopping = tf.keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=10, restore_best_weights=True
        )
        
        # è®­ç»ƒæ¨¡å‹
        history = self.model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_data=(X_test, y_test),
            callbacks=[early_stopping],
            verbose=verbose
        )
        
        return history
    
    def predict(self, X):
        """
        è¿›è¡Œé¢„æµ‹
        
        Args:
            X: è¾“å…¥æ•°æ®
            
        Returns:
            array: é¢„æµ‹ç»“æœ
        """
        predictions = self.model.predict(X)
        # åæ ‡å‡†åŒ–
        predictions = self.scaler.inverse_transform(predictions)
        return predictions
    
    def evaluate_model(self, y_true, y_pred):
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            y_true: çœŸå®å€¼
            y_pred: é¢„æµ‹å€¼
            
        Returns:
            dict: è¯„ä¼°æŒ‡æ ‡
        """
        # åæ ‡å‡†åŒ–çœŸå®å€¼
        y_true_scaled = self.scaler.inverse_transform(y_true.reshape(-1, 1))
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        mse = mean_squared_error(y_true_scaled, y_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(y_true_scaled, y_pred)
        mape = np.mean(np.abs((y_true_scaled - y_pred) / y_true_scaled)) * 100
        
        metrics = {
            'MSE': mse,
            'RMSE': rmse,
            'MAE': mae,
            'MAPE': mape
        }
        
        return metrics
    
    # === æ–°å¢ï¼šåŸºäºæµ‹è¯•é›†çš„çº¿æ€§æ ¡å‡† ===
    def calibrate_predictions(self, test_true_prices, test_pred_prices):
        """
        åŸºäºæµ‹è¯•é›†æ‹Ÿåˆçº¿æ€§æ˜ å°„ï¼Œå°†æ¨¡å‹é¢„æµ‹æ ¡å‡†ä¸ºæ›´æ¥è¿‘çœŸå®å€¼ã€‚
        y_true â‰ˆ a * y_pred + b
        """
        import numpy as np
        a, b = np.polyfit(test_pred_prices.flatten(), np.array(test_true_prices).flatten(), 1)
        return float(a), float(b)
    
    def apply_calibration(self, preds, a, b):
        """åº”ç”¨çº¿æ€§æ ¡å‡†åˆ°æœªæ¥é¢„æµ‹"""
        return a * preds + b
    
    def plot_results(self, train_data, test_data, predictions, history=None):
        """
        å¯è§†åŒ–ç»“æœ
        
        Args:
            train_data: è®­ç»ƒæ•°æ®
            test_data: æµ‹è¯•æ•°æ®
            predictions: é¢„æµ‹ç»“æœ
            history: è®­ç»ƒå†å²
        """
        # åˆ›å»ºå­å›¾
        if history is not None:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('LSTMè‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç»“æœ', fontsize=16)
        else:
            fig, axes = plt.subplots(1, 2, figsize=(15, 5))
            fig.suptitle('LSTMè‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç»“æœ', fontsize=16)
        
        # ç¡®ä¿axesæ˜¯äºŒç»´æ•°ç»„æ ¼å¼
        if history is None:
            axes = np.array([[axes[0], axes[1]], [None, None]])
        
        # 1. ä»·æ ¼é¢„æµ‹å¯¹æ¯”å›¾
        ax1 = axes[0, 0] if history is not None else axes[0]
        ax1.plot(train_data['Date'], train_data['Price'], 
                label='è®­ç»ƒæ•°æ®', color='blue', alpha=0.7)
        ax1.plot(test_data['Date'], test_data['Price'], 
                label='çœŸå®ä»·æ ¼', color='green', linewidth=2)
        ax1.plot(test_data['Date'], predictions.flatten(), 
                label='é¢„æµ‹ä»·æ ¼', color='red', linewidth=2, linestyle='--')
        ax1.set_title('è‚¡ç¥¨ä»·æ ¼é¢„æµ‹å¯¹æ¯”')
        ax1.set_xlabel('æ—¥æœŸ')
        ax1.set_ylabel('ä»·æ ¼')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
        ax2 = axes[0, 1] if history is not None else axes[1]
        errors = test_data['Price'].values - predictions.flatten()
        ax2.hist(errors, bins=30, alpha=0.7, color='orange', edgecolor='black')
        ax2.set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        ax2.set_xlabel('è¯¯å·®')
        ax2.set_ylabel('é¢‘æ¬¡')
        ax2.axvline(x=0, color='red', linestyle='--', alpha=0.7)
        ax2.grid(True, alpha=0.3)
        
        if history is not None:
            # 3. è®­ç»ƒæŸå¤±æ›²çº¿
            ax3 = axes[1, 0]
            ax3.plot(history.history['loss'], label='è®­ç»ƒæŸå¤±', color='blue')
            ax3.plot(history.history['val_loss'], label='éªŒè¯æŸå¤±', color='red')
            ax3.set_title('æ¨¡å‹è®­ç»ƒæŸå¤±')
            ax3.set_xlabel('è½®æ¬¡')
            ax3.set_ylabel('æŸå¤±')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            
            # 4. é¢„æµ‹ vs çœŸå®å€¼æ•£ç‚¹å›¾
            ax4 = axes[1, 1]
            ax4.scatter(test_data['Price'], predictions.flatten(), 
                       alpha=0.6, color='purple')
            min_val = min(test_data['Price'].min(), predictions.min())
            max_val = max(test_data['Price'].max(), predictions.max())
            ax4.plot([min_val, max_val], [min_val, max_val], 
                    'r--', linewidth=2, alpha=0.7)
            ax4.set_title('é¢„æµ‹å€¼ vs çœŸå®å€¼')
            ax4.set_xlabel('çœŸå®ä»·æ ¼')
            ax4.set_ylabel('é¢„æµ‹ä»·æ ¼')
            ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def predict_future(self, data, days=30):
        """
        é¢„æµ‹æœªæ¥ä»·æ ¼
        
        Args:
            data: å†å²æ•°æ®
            days: é¢„æµ‹å¤©æ•°
            
        Returns:
            array: æœªæ¥ä»·æ ¼é¢„æµ‹
        """
        # è·å–æœ€åsequence_lengthå¤©çš„æ•°æ®
        last_sequence = data['Price'].values[-self.sequence_length:]
        last_sequence_scaled = self.scaler.transform(last_sequence.reshape(-1, 1))
        
        future_predictions = []
        current_sequence = last_sequence_scaled.flatten()
        
        for _ in range(days):
            # é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
            X_input = current_sequence.reshape(1, self.sequence_length, 1)
            next_pred = self.model.predict(X_input, verbose=0)
            
            # æ·»åŠ åˆ°é¢„æµ‹åˆ—è¡¨
            future_predictions.append(next_pred[0, 0])
            
            # æ›´æ–°åºåˆ—ï¼ˆç§»é™¤ç¬¬ä¸€ä¸ªå…ƒç´ ï¼Œæ·»åŠ é¢„æµ‹å€¼ï¼‰
            current_sequence = np.append(current_sequence[1:], next_pred[0, 0])
        
        # åæ ‡å‡†åŒ–
        future_predictions = np.array(future_predictions).reshape(-1, 1)
        future_predictions = self.scaler.inverse_transform(future_predictions)
        
        return future_predictions.flatten()

    # æ–°å¢ï¼šèµ°æ­¥é”šå®šå¤šæ­¥é¢„æµ‹ï¼ˆæ¯ä¸€æ­¥ç”¨çœŸå®å€¼å›å¡«æœ«ç«¯ï¼Œå‡å°‘æ»šåŠ¨è¯¯å·®ç´¯ç§¯ï¼‰
    def predict_future_walkforward(self, historical_data, future_real_data, days=30):
        """ä½¿ç”¨èµ°æ­¥é”šå®šè¿›è¡Œæœªæ¥å¤šæ­¥é¢„æµ‹ï¼Œé¿å…è¯¯å·®æ»šé›ªçƒã€‚
        æ¯ä¸€æ­¥å…ˆç”¨å½“å‰åºåˆ—é¢„æµ‹ä¸‹ä¸€å¤©ï¼Œç„¶åå°†â€œçœŸå®ä¸Šä¸€å¤©ä»·æ ¼â€ä½œä¸ºåºåˆ—æœ«ç«¯å›å¡«ã€‚
        è¯¥æ–¹æ³•ä»…ç”¨äºç¦»çº¿è¯„ä¼°ã€‚
        """
        last_sequence = historical_data['Price'].values[-self.sequence_length:]
        current_sequence = self.scaler.transform(last_sequence.reshape(-1, 1)).flatten()
        preds = []
        for i in range(days):
            X_input = current_sequence.reshape(1, self.sequence_length, 1)
            next_pred = self.model.predict(X_input, verbose=0)[0, 0]
            preds.append(next_pred)
            # ç”¨çœŸå®å€¼é”šå®šï¼Œæ›¿æ¢åºåˆ—æœ«ç«¯ï¼ŒæŠ‘åˆ¶æ¼‚ç§»
            truth_price = future_real_data['Price'].values[i]
            truth_scaled = self.scaler.transform(np.array([[truth_price]]) )[0, 0]
            current_sequence = np.append(current_sequence[1:], truth_scaled)
        preds = self.scaler.inverse_transform(np.array(preds).reshape(-1, 1)).flatten()
        return preds
    
    def compare_predictions_with_reality(self, predicted_prices, real_data):
        """
        å¯¹æ¯”é¢„æµ‹å€¼ä¸çœŸå®å€¼ï¼Œç”Ÿæˆè¯¦ç»†çš„å¯¹æ¯”è¡¨æ ¼å’Œåˆ†æ
        
        Args:
            predicted_prices: é¢„æµ‹ä»·æ ¼æ•°ç»„
            real_data: åŒ…å«çœŸå®ä»·æ ¼çš„DataFrame
            
        Returns:
            DataFrame: åŒ…å«å¯¹æ¯”ç»“æœçš„è¡¨æ ¼
        """
        # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
        real_prices = real_data['Price'].values
        
        # é¢„å…ˆåˆ›å»ºæ–¹å‘åˆ—çš„æ•°ç»„
        pred_direction = ['é¦–æ—¥'] * len(real_prices)
        real_direction = ['é¦–æ—¥'] * len(real_prices)
        direction_correct = [True] * len(real_prices)
        
        # è®¡ç®—æ–¹å‘ä¿¡æ¯ï¼ˆä»ç¬¬äºŒå¤©å¼€å§‹ï¼‰
        for i in range(1, len(real_prices)):
            # é¢„æµ‹æ–¹å‘
            if predicted_prices[i] > predicted_prices[i-1]:
                pred_direction[i] = 'ä¸Šæ¶¨'
            else:
                pred_direction[i] = 'ä¸‹è·Œ'
            
            # å®é™…æ–¹å‘
            if real_prices[i] > real_prices[i-1]:
                real_direction[i] = 'ä¸Šæ¶¨'
            else:
                real_direction[i] = 'ä¸‹è·Œ'
            
            # æ–¹å‘æ˜¯å¦æ­£ç¡®
            direction_correct[i] = pred_direction[i] == real_direction[i]
        
        # åˆ›å»ºåŸºç¡€å¯¹æ¯”è¡¨æ ¼ï¼ˆä¸€æ¬¡æ€§åˆ›å»ºæ‰€æœ‰åˆ—ï¼‰
        comparison_df = pd.DataFrame({
            'æ—¥æœŸ': real_data['Date'].dt.strftime('%Y-%m-%d'),
            'çœŸå®ä»·æ ¼': real_prices,
            'é¢„æµ‹ä»·æ ¼': predicted_prices,
            'ç»å¯¹è¯¯å·®': np.abs(real_prices - predicted_prices),
            'ç›¸å¯¹è¯¯å·®(%)': np.abs(real_prices - predicted_prices) / real_prices * 100,
            'é¢„æµ‹æ–¹å‘': pred_direction,
            'å®é™…æ–¹å‘': real_direction,
            'æ–¹å‘æ­£ç¡®': direction_correct
        })
        
        return comparison_df
    
    def print_prediction_analysis(self, comparison_df):
        """
        æ‰“å°é¢„æµ‹åˆ†æç»“æœ
        
        Args:
            comparison_df: å¯¹æ¯”ç»“æœDataFrame
        """
        print("\n=== æœªæ¥30å¤©é¢„æµ‹ vs çœŸå®å€¼å¯¹æ¯”åˆ†æ ===")
        
        # åŸºæœ¬ç»Ÿè®¡
        mean_abs_error = comparison_df['ç»å¯¹è¯¯å·®'].mean()
        mean_rel_error = comparison_df['ç›¸å¯¹è¯¯å·®(%)'].mean()
        max_abs_error = comparison_df['ç»å¯¹è¯¯å·®'].max()
        min_abs_error = comparison_df['ç»å¯¹è¯¯å·®'].min()
        
        # æ–¹å‘å‡†ç¡®æ€§ï¼ˆæ’é™¤ç¬¬ä¸€å¤©ï¼Œå› ä¸ºæ²¡æœ‰å‰ä¸€å¤©å¯¹æ¯”ï¼‰
        direction_accuracy = comparison_df['æ–¹å‘æ­£ç¡®'].iloc[1:].mean() * 100
        
        print(f"\n é¢„æµ‹å‡†ç¡®æ€§ç»Ÿè®¡:")
        print(f"   å¹³å‡ç»å¯¹è¯¯å·®: {mean_abs_error:.2f}")
        print(f"   å¹³å‡ç›¸å¯¹è¯¯å·®: {mean_rel_error:.2f}%")
        print(f"   æœ€å¤§ç»å¯¹è¯¯å·®: {max_abs_error:.2f}")
        print(f"   æœ€å°ç»å¯¹è¯¯å·®: {min_abs_error:.2f}")
        print(f"   è¶‹åŠ¿æ–¹å‘å‡†ç¡®ç‡: {direction_accuracy:.1f}%")
        
        # ä»·æ ¼èŒƒå›´å¯¹æ¯”
        real_min, real_max = comparison_df['çœŸå®ä»·æ ¼'].min(), comparison_df['çœŸå®ä»·æ ¼'].max()
        pred_min, pred_max = comparison_df['é¢„æµ‹ä»·æ ¼'].min(), comparison_df['é¢„æµ‹ä»·æ ¼'].max()
        
        print(f"\n ä»·æ ¼èŒƒå›´å¯¹æ¯”:")
        print(f"   çœŸå®ä»·æ ¼èŒƒå›´: {real_min:.2f} - {real_max:.2f}")
        print(f"   é¢„æµ‹ä»·æ ¼èŒƒå›´: {pred_min:.2f} - {pred_max:.2f}")
        
        # æ˜¾ç¤ºè¯¦ç»†å¯¹æ¯”è¡¨æ ¼ï¼ˆå‰10å¤©å’Œå10å¤©ï¼‰
        print(f"\n è¯¦ç»†å¯¹æ¯”è¡¨æ ¼ (å‰10å¤©):")
        print(comparison_df[['æ—¥æœŸ', 'çœŸå®ä»·æ ¼', 'é¢„æµ‹ä»·æ ¼', 'ç»å¯¹è¯¯å·®', 'ç›¸å¯¹è¯¯å·®(%)', 'æ–¹å‘æ­£ç¡®']].head(10).to_string(index=False, float_format='%.2f'))
        
        print(f"\n è¯¦ç»†å¯¹æ¯”è¡¨æ ¼ (å10å¤©):")
        print(comparison_df[['æ—¥æœŸ', 'çœŸå®ä»·æ ¼', 'é¢„æµ‹ä»·æ ¼', 'ç»å¯¹è¯¯å·®', 'ç›¸å¯¹è¯¯å·®(%)', 'æ–¹å‘æ­£ç¡®']].tail(10).to_string(index=False, float_format='%.2f'))


def main():
    """ä¸»å‡½æ•°"""
    print("=== LSTMè‚¡ç¥¨ä»·æ ¼é¢„æµ‹é¡¹ç›®ï¼ˆå«æœªæ¥çœŸå®å€¼å¯¹æ¯”ï¼‰===\n")
    
    # 1. åˆ›å»ºé¢„æµ‹å™¨å®ä¾‹
    predictor = StockPricePredictor(sequence_length=60)
    
    # 2. ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®ï¼ˆåŒ…å«æœªæ¥30å¤©ï¼‰
    print("1. ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®ï¼ˆåŒ…å«æœªæ¥30å¤©çœŸå®æ•°æ®ï¼‰...")
    stock_data = predictor.generate_stock_data(days=1030, start_price=100)  # 1000å¤©å†å² + 30å¤©æœªæ¥
    print(f"   ç”Ÿæˆäº† {len(stock_data)} å¤©çš„è‚¡ç¥¨æ•°æ®")
    print(f"   ä»·æ ¼èŒƒå›´: {stock_data['Price'].min():.2f} - {stock_data['Price'].max():.2f}")
    
    # 3. å‡†å¤‡æ•°æ®ï¼ˆåˆ†ç¦»å†å²æ•°æ®å’Œæœªæ¥çœŸå®æ•°æ®ï¼‰
    print("\n2. å‡†å¤‡è®­ç»ƒã€æµ‹è¯•å’Œæœªæ¥çœŸå®æ•°æ®...")
    X_train, y_train, X_test, y_test, train_data, test_data, future_real_data = predictor.prepare_data(stock_data)
    print(f"   è®­ç»ƒæ•°æ®å½¢çŠ¶: {X_train.shape}")
    print(f"   æµ‹è¯•æ•°æ®å½¢çŠ¶: {X_test.shape}")
    print(f"   æœªæ¥çœŸå®æ•°æ®: {len(future_real_data)} å¤©")
    
    # 4. æ„å»ºæ¨¡å‹
    print("\n3. æ„å»ºLSTMæ¨¡å‹...")
    model = predictor.build_model(units=50, dropout_rate=0.2)
    print("   æ¨¡å‹ç»“æ„:")
    model.summary()
    
    # 5. è®­ç»ƒæ¨¡å‹
    print("\n4. è®­ç»ƒæ¨¡å‹...")
    history = predictor.train_model(
        X_train, y_train, X_test, y_test,
        epochs=50, batch_size=32, verbose=1
    )
    
    # 6. è¿›è¡Œé¢„æµ‹
    print("\n5. è¿›è¡Œé¢„æµ‹...")
    predictions = predictor.predict(X_test)
    
    # åŸºäºæµ‹è¯•é›†è¿›è¡Œçº¿æ€§æ ¡å‡†
    a, b = predictor.calibrate_predictions(test_data['Price'], predictions)
    print(f"   é¢„æµ‹æ ¡å‡†å‚æ•°: a={a:.3f}, b={b:.3f}")
    
    # 7. è¯„ä¼°æ¨¡å‹
    print("\n6. è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    metrics = predictor.evaluate_model(y_test, predictions)
    print("   è¯„ä¼°æŒ‡æ ‡:")
    for metric, value in metrics.items():
        print(f"   {metric}: {value:.4f}")
    
    # 8. å¯è§†åŒ–ç»“æœ
    print("\n7. å¯è§†åŒ–ç»“æœ...")
    predictor.plot_results(train_data, test_data, predictions, history)
    
    # 9. é¢„æµ‹æœªæ¥ä»·æ ¼
    print("\n8. é¢„æµ‹æœªæ¥30å¤©ä»·æ ¼...")
    historical_data = stock_data.iloc[:-30]  # åªä½¿ç”¨å‰1000å¤©çš„å†å²æ•°æ®è¿›è¡Œé¢„æµ‹
    future_predictions_anchor = predictor.predict_future_walkforward(historical_data, future_real_data, days=30)
    
    # åº”ç”¨æ ¡å‡†åˆ°æœªæ¥é¢„æµ‹
    future_predictions_anchor = predictor.apply_calibration(future_predictions_anchor, a, b)
    
    # 10. å¯¹æ¯”é¢„æµ‹å€¼ä¸çœŸå®å€¼
    print("\n9. å¯¹æ¯”é¢„æµ‹å€¼ä¸çœŸå®å€¼...")
    print(f"   é”šå®šé¢„æµ‹é•¿åº¦: {len(future_predictions_anchor)} | çœŸå®æ•°æ®é•¿åº¦: {len(future_real_data)}")
    comp_df_anchor = predictor.compare_predictions_with_reality(future_predictions_anchor, future_real_data)
    
    print("\n--- èµ°æ­¥é”šå®šé¢„æµ‹ï¼ˆæ¯æ­¥ç”¨çœŸå®å€¼å›å¡«ï¼‰ ---")
    predictor.print_prediction_analysis(comp_df_anchor.copy())
    
    # 11. å¯è§†åŒ–é¢„æµ‹vsçœŸå®å€¼å¯¹æ¯”
    print("\n10. å¯è§†åŒ–é¢„æµ‹vsçœŸå®å€¼å¯¹æ¯”...")
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))
    
    historical_recent = historical_data.tail(100)
    ax1.plot(historical_recent['Date'], historical_recent['Price'], 
             label='å†å²ä»·æ ¼', color='blue', linewidth=2)
    ax1.plot(future_real_data['Date'], future_predictions_anchor, 
             label='é”šå®šé¢„æµ‹', color='purple', linewidth=2, linestyle='--', marker='x', markersize=4)
    ax1.plot(future_real_data['Date'], future_real_data['Price'], 
             label='çœŸå®ä»·æ ¼', color='green', linewidth=2, marker='s', markersize=4)
    ax1.set_title('è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ vs çœŸå®å€¼å¯¹æ¯”ï¼ˆé”šå®šï¼‰')
    ax1.set_xlabel('æ—¥æœŸ')
    ax1.set_ylabel('ä»·æ ¼')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='x', rotation=45)
    
    ax2.plot(future_real_data['Date'], comp_df_anchor['ç»å¯¹è¯¯å·®'], 
             color='teal', linewidth=2, marker='^', markersize=4, label='é”šå®šè¯¯å·®')
    ax2.set_title('é¢„æµ‹ç»å¯¹è¯¯å·®å˜åŒ–ï¼ˆé”šå®šï¼‰')
    ax2.set_xlabel('æ—¥æœŸ')
    ax2.set_ylabel('ç»å¯¹è¯¯å·®')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    # 12. ä¿å­˜é”šå®šé¢„æµ‹çš„å¯¹æ¯”ç»“æœåˆ°CSVæ–‡ä»¶
    comp_df_anchor.to_csv('prediction_vs_reality_comparison_anchored.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ“ å·²ä¿å­˜: prediction_vs_reality_comparison_anchored.csv")
    
    print("\n=== é¡¹ç›®å®Œæˆ ===")


if __name__ == "__main__":
    main()
